# Ethics in Tech

## Ethics in the Workplace
[Notes taken from this article](https://www.vox.com/2018/8/17/17704526/google-dragonfly-censored-search-engine-china)

- Google's project Dragonfly is a censored search engine for users in China.
- Many of Google employees protested about the lack of transparency and details about the project.
- Employees were concerned about their lack of input and discretion when it comes to what contracts Google accepts.
- They were concerened about the morality and a contradiction of Google's own ethical principles.
- The censored search engine could block users from accessing sites about democracy, human rights, and peaceful protests.
- A similar protest happened in April, when employees objected to the use of AI to analyze drone footage when looking for human targets for the Pentagon/military.
- >In their letter to executives, Google employees make four specific demands. First, they want the company to create a structure to allow rank-and-file employees to review ethical issues in company projects. Second, they want the company to appoint an ombudsman to oversee the ethics review process, with input from employees over who fills the position. Third, they want a plan to ensure Google is transparent with employees about the purpose of the technology the company is developing, so employees can make informed choices about the ethical implications of the work they do. Fourth, they want the company to publish ethical assessments of their projects, such as Dragonfly, and to communicate regularly with employees about issues of concern.
- Overall, I agree that technology needs to be used for the betterment of humanity and not just for profit. I also agree that employees need a voice when it comes to company decisions tied to ethical issues.
- Quote from Brandon Downey, a former Google engineer: 
>Google is acting like a traditional company; one that squeezes every dime out of the marketplace, heedless of intangibles like principle, ethical cost, and even at the risk of the safety of its users...If technology is a tool, then it means the people making that tool have a responsibility to curb their tool’s misuse by playing a role in the decisions on how it gets used. And if the people who are the leaders of the company don’t believe this, they should hear it in plainer and clearer terms: namely, you do not become one of the largest companies in the history of capitalism without the assistance of the workers making those tools.

## Ethics in Technology
[Notes taken from this article](https://www.theglobeandmail.com/globe-drive/culture/technology/the-ethical-dilemmas-of-self-drivingcars/article37803470/)

- For a self-driving car, who should be the prioriy to save when it comes to an unavoidable accident? The driver? Pedestrian? Children or the elderly?
- Germany tried to establish some guidelines. Human lives should always be the priory over animals or property. Minimize human death and don't discriminate between age, gender, or other factors.
- According to a study published by *Science* in 2016, the majority of people want their self-driving car to prioritize the passenger's safety over everything else.
- In practice, human instincts will lean towards self-preservation over ethics especially when it comes to split-second life-or-death situations.
- In my opinion, I agree that self-driving cars should be programmed to pick the option that leads to the least amount of human death. But in reality, I would not be comfortable buying/owning/riding a car that could potentially decide that my death is the best outcome during an accident.

[Back to HOME](../README.md)